{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter sentiment Analysis using TextBlob and tweepy\n",
    "\n",
    "This is a little project to test out the TextBlob library for sentiment analysis\n",
    "\n",
    "## import + configurations\n",
    "\n",
    "In here we import different libraries to use in our code. Like **tweepy** (twitter python API), **re** for regex expressions and **TextBlob** for sentiment analysis. We also use **csv** to save the result into a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import sys\n",
    "import csv\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also using dict to format the text so that we don't have encoding errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we set the twitter API configurations and get an instance of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'CONSUMER_KEY'\n",
    "consumer_secret = 'CONSUMER_SECRET'\n",
    "access_token = 'ACCESS_TOKEN'\n",
    "access_secret = 'ACCESS_SECRET'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we set some configuration variables like the search query *(searchQuery)*, the number of tweets *(maxTweets)* and the *headers* for the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchQuery = 'Trump'\n",
    "maxTweets = 1000\n",
    "acceptedCharsRegex = '[^0-9a-zA-Z.:/()&@-_=+;?!*\\']+'\n",
    "# header for csv file\n",
    "headers = [\n",
    "    'tweet', \n",
    "    'created_at',\n",
    "    'word_count',\n",
    "    'favorite_count', \n",
    "    'retweet_count',\n",
    "    'user_followers_count',\n",
    "    'user_following_count',\n",
    "    'user_friends_count',\n",
    "    'user_verified',\n",
    "    'subjectivity', \n",
    "    'polarity', \n",
    "    'sentiment'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a new function *(get_sentiment)* that returns the label for our data. It uses a *threshold* as a configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = {'neutral_min': -0.02, 'neutral_max': 0.25}\n",
    "\n",
    "# function to get the sentiment\n",
    "def get_sentiment(text, analysis):\n",
    "    if(analysis.sentiment.polarity < threshold['neutral_min']):\n",
    "        return \"Negative\"\n",
    "    elif(analysis.sentiment.polarity >= threshold['neutral_max']):\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here, we create our *.csv* file and we write the *headers* in it. Then, we loop for tweets using the *searchQuery* specified in the configuration section.<br>\n",
    "For every tweet, we get it's full text and we create with it a TextBlob instance. Then we get some *features* to save into the *.csv* file.<br>\n",
    "And lastly, we return, with the *get_sentiment* function, the label for that tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('trump_twitter.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow(headers)\n",
    "    for tweet in tweepy.Cursor(api.search,q=searchQuery, tweet_mode='extended').items(maxTweets):\n",
    "        # getting the tweet dict\n",
    "        # print(tweet.__dict__)\n",
    "        \n",
    "        # cleaning the tweet text of special chars\n",
    "        tweetText = re.sub(acceptedCharsRegex, ' ', tweet.full_text.translate(non_bmp_map))\n",
    "        \n",
    "        # creating the TextBlobObject for analysis\n",
    "        analysis = TextBlob(tweetText)\n",
    "        \n",
    "        # saving all the information into an array\n",
    "        tweetInfos = [\n",
    "            tweetText, \n",
    "            tweet.created_at.strftime('%Y-%m-%d'),\n",
    "            analysis.words.__sizeof__(), \n",
    "            tweet.favorite_count,\n",
    "            tweet.retweet_count,\n",
    "            tweet.user.followers_count,\n",
    "            tweet.user.following,\n",
    "            tweet.user.friends_count,\n",
    "            tweet.user.verified,\n",
    "            analysis.sentiment.subjectivity, \n",
    "            analysis.sentiment.polarity,\n",
    "            get_sentiment(tweetText,analysis)\n",
    "        ]\n",
    "        \n",
    "        # print(tweetInfos)\n",
    "        \n",
    "        # writing the array in the csv file\n",
    "        writer.writerow(tweetInfos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
